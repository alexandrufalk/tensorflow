{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMoRO7ZnN/766WIlXWk5yuP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexandrufalk/tensorflow/blob/Master/SRGAN_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qm2AzkIBkZxF"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, optimizers\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define the Generator\n",
        "-residual blocks and upsampling layers to convert low-resolution images to high-resolution images.\n",
        "\n",
        "-A residual block helps in training deeper networks by allowing gradients to flow through skip connections."
      ],
      "metadata": {
        "id": "pCZeSDPAkiyS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def residual_block(input_tensor, filters=64, kernel_size=3):\n",
        "    x = layers.Conv2D(filters, kernel_size, padding='same')(input_tensor)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.PReLU(shared_axes=[1, 2])(x)\n",
        "    x = layers.Conv2D(filters, kernel_size, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Add()([x, input_tensor])\n",
        "    return x"
      ],
      "metadata": {
        "id": "sWCVCCuCkfxn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Upsampling Block\n",
        "Uses PixelShuffle (sub-pixel convolution) to upscale the image.\n"
      ],
      "metadata": {
        "id": "qC_hXvVpMUbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def upsample_block(input_tensor, filters=256, kernel_size=3, scale=2):\n",
        "    x = layers.Conv2D(filters, kernel_size, padding='same')(input_tensor)\n",
        "    x = layers.Lambda(lambda x: tf.nn.depth_to_space(x, scale))(x)\n",
        "    x = layers.PReLU(shared_axes=[1, 2])(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "2QNSxaa7MbyC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Generator Model"
      ],
      "metadata": {
        "id": "32lOExsMMiat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_generator(hr_shape):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        hr_shape: tuple, high-resolution image shape, e.g., (None, None, 3)\n",
        "    Returns:\n",
        "        Keras Model\n",
        "    \"\"\"\n",
        "    inputs = layers.Input(shape=(None, None, 3))\n",
        "\n",
        "    # Initial Conv layer\n",
        "    x = layers.Conv2D(64, 9, padding='same')(inputs)\n",
        "    x = layers.PReLU(shared_axes=[1, 2])(x)\n",
        "    residual = x\n",
        "\n",
        "    # 16 Residual blocks\n",
        "    for _ in range(16):\n",
        "        residual = residual_block(residual)\n",
        "\n",
        "    # Conv layer after residual blocks\n",
        "    x = layers.Conv2D(64, 3, padding='same')(residual)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Add()([x, inputs])\n",
        "\n",
        "    # Upsampling blocks\n",
        "    x = upsample_block(x)\n",
        "    x = upsample_block(x)\n",
        "\n",
        "    # Output layer\n",
        "    outputs = layers.Conv2D(3, 9, padding='same', activation='tanh')(x)\n",
        "\n",
        "    model = models.Model(inputs, outputs, name='Generator')\n",
        "    return model"
      ],
      "metadata": {
        "id": "oq4O00SUMiIO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define the Discriminator\n",
        "The discriminator is a CNN that classifies images as real or fake."
      ],
      "metadata": {
        "id": "XVWIqs8KQVV1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_discriminator(hr_shape):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        hr_shape: tuple, high-resolution image shape, e.g., (None, None, 3)\n",
        "    Returns:\n",
        "        Keras Model\n",
        "    \"\"\"\n",
        "    inputs = layers.Input(shape=hr_shape)\n",
        "\n",
        "    x = layers.Conv2D(64, 3, strides=1, padding='same')(inputs)\n",
        "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    # 15 Convolutional blocks\n",
        "    filters = 64\n",
        "    for i in range(1, 16):\n",
        "        if i % 2 == 0:\n",
        "            strides = 2\n",
        "            filters *= 2\n",
        "        else:\n",
        "            strides = 1\n",
        "        x = layers.Conv2D(filters, 3, strides=strides, padding='same')(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dense(1024)(x)\n",
        "    x = layers.LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "    model = models.Model(inputs, outputs, name='Discriminator')\n",
        "    return model"
      ],
      "metadata": {
        "id": "pTQxSJNMMeS6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define the SRGAN Model\n",
        "\n",
        "Combines the generator and discriminator. The discriminator is used to compute the adversarial loss for the generator."
      ],
      "metadata": {
        "id": "2qtb8nrPQzy1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_srgan(generator, discriminator, vgg):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        generator: Keras Model, generator model\n",
        "        discriminator: Keras Model, discriminator model\n",
        "        vgg: Keras Model, pre-trained VGG model for perceptual loss\n",
        "    Returns:\n",
        "        Keras Model\n",
        "    \"\"\"\n",
        "    discriminator.trainable = False\n",
        "    sr = generator.output\n",
        "    vgg_features = vgg(sr)\n",
        "    validity = discriminator(sr)\n",
        "\n",
        "    model = models.Model(generator.input, [validity, vgg_features])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "3IGuE8RFQxBn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Define Loss Functions\n",
        "Mean Squared Error between the generated image and the ground truth high-resolution image."
      ],
      "metadata": {
        "id": "GkQmaWxLRGsx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def content_loss(y_true, y_pred):\n",
        "    return tf.reduce_mean(tf.square(y_true - y_pred))"
      ],
      "metadata": {
        "id": "P60-odByRHh2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Adversarial Loss - Binary cross-entropy loss to train the generator to fool the discriminator.\n",
        "adversarial_loss = tf.keras.losses.BinaryCrossentropy()"
      ],
      "metadata": {
        "id": "QbSMcb8NRSQC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Perceptual Loss\n",
        "Uses feature maps from a pre-trained VGG19 network to compute the loss."
      ],
      "metadata": {
        "id": "RPEr_JWaRrp9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-trained VGG19 model + higher level layers\n",
        "def build_vgg():\n",
        "    vgg = VGG19(weights='imagenet', include_top=False, input_shape=(None, None, 3))\n",
        "    vgg.trainable = False\n",
        "    # Select the output of 'block5_conv4' for perceptual loss\n",
        "    output = vgg.get_layer('block5_conv4').output\n",
        "    model = models.Model(vgg.input, output)\n",
        "    return model\n",
        "\n",
        "vgg = build_vgg()\n",
        "\n",
        "def perceptual_loss(y_true, y_pred):\n",
        "    y_true_features = vgg(y_true)\n",
        "    y_pred_features = vgg(y_pred)\n",
        "    return tf.reduce_mean(tf.square(y_true_features - y_pred_features))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yr68_uudRWQe",
        "outputId": "185bff43-2748-4d0f-811e-07579aeaedde"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m80134624/80134624\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
          ]
        }
      ]
    }
  ]
}