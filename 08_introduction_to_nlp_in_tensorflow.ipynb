{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOFe2y8xs+aSMdi7BH2623j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexandrufalk/tensorflow/blob/Master/08_introduction_to_nlp_in_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The main goal of natural language processing (NLP) is to derive information from natural language.\n",
        "\n",
        "Natural language is a broad term but you can consider it to cover any of the following:\n",
        "\n",
        "Text (such as that contained in an email, blog post, book, Tweet)\n",
        "Speech (a conversation you have with a doctor, voice commands you give to a smart speaker)"
      ],
      "metadata": {
        "id": "zR-iQs8-C9Ps"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVI_U4wgClz6",
        "outputId": "ca26ae3a-ce29-4630-e75a-b12eadbbf2f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-fdf33385-84df-6158-1d33-b749b6667763)\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download helper functions script\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Prl9JELiDFQV",
        "outputId": "8a3bcbdc-33a9-409c-c2af-6bbe9599018d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-18 11:07:16--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-06-18 11:07:16 (123 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import series of helper functions for the notebook\n",
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "metadata": {
        "id": "XD1uam0nDt6N"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download a text dataset"
      ],
      "metadata": {
        "id": "Ko8saxy2D17n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download data (same as from Kaggle)\n",
        "!wget \"https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\"\n",
        "\n",
        "# Unzip data\n",
        "unzip_data(\"nlp_getting_started.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKZ7a1IbDvyV",
        "outputId": "2c9d1d6f-d7c8-479e-8fd4-fc115871b5d3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-18 11:07:17--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.197.207, 74.125.135.207, 74.125.142.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.197.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "\rnlp_getting_started   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.004s  \n",
            "\n",
            "2024-06-18 11:07:17 (154 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn .csv files into pandas DataFrame's\n",
        "import pandas as pd\n",
        "train_df=pd.read_csv(\"train.csv\")\n",
        "test_df=pd.read_csv(\"test.csv\")\n",
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "cJGdHn5IEXym",
        "outputId": "4cad5ba8-def7-4786-ae16-9ba29f843568"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text  \\\n",
              "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
              "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
              "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
              "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
              "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
              "\n",
              "   target  \n",
              "0       1  \n",
              "1       1  \n",
              "2       1  \n",
              "3       1  \n",
              "4       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5aa97029-2163-442f-b732-6903d1578e8f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5aa97029-2163-442f-b732-6903d1578e8f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5aa97029-2163-442f-b732-6903d1578e8f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5aa97029-2163-442f-b732-6903d1578e8f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b3b7816d-4743-4754-b06b-257202b01974\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b3b7816d-4743-4754-b06b-257202b01974')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b3b7816d-4743-4754-b06b-257202b01974 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 7613,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3137,\n        \"min\": 1,\n        \"max\": 10873,\n        \"num_unique_values\": 7613,\n        \"samples\": [\n          3796,\n          3185,\n          7769\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"keyword\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 221,\n        \"samples\": [\n          \"injury\",\n          \"nuclear%20reactor\",\n          \"engulfed\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"location\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3341,\n        \"samples\": [\n          \"Oklahoma\",\n          \"Starling City\",\n          \"Trinidad and Tobago\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7503,\n        \"samples\": [\n          \"Three Homes Demolished in Unrecognized Arab Village - International Middle East Media Center http://t.co/ik8m4Yi9T4\",\n          \"Reid Lake fire prompts campground evacuation order http://t.co/jBODKM6rBU\",\n          \"FAAN orders evacuation of abandoned aircraft at MMA http://t.co/dEvYbnVXGQ via @todayng\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle training dataframe\n",
        "train_df_shuffled=train_df.sample(frac=1,random_state=42) # shuffle with random_state=42 for reproducibility\n",
        "train_df_shuffled.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "WoiyzsAyMnSU",
        "outputId": "6b9aae52-35c3-4782-8b8d-5c149c279a5d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id      keyword               location  \\\n",
              "2644  3796  destruction                    NaN   \n",
              "2227  3185       deluge                    NaN   \n",
              "5448  7769       police                     UK   \n",
              "132    191   aftershock                    NaN   \n",
              "6845  9810       trauma  Montgomery County, MD   \n",
              "\n",
              "                                                   text  target  \n",
              "2644  So you have a new weapon that can cause un-ima...       1  \n",
              "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
              "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
              "132   Aftershock back to school kick off was great. ...       0  \n",
              "6845  in response to trauma Children of Addicts deve...       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-66a231d6-ae4e-4c83-a6f3-f3268fdf11a6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-66a231d6-ae4e-4c83-a6f3-f3268fdf11a6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-66a231d6-ae4e-4c83-a6f3-f3268fdf11a6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-66a231d6-ae4e-4c83-a6f3-f3268fdf11a6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e7a9dd4e-29e8-4d5b-9018-a39e1cf3ccb8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e7a9dd4e-29e8-4d5b-9018-a39e1cf3ccb8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e7a9dd4e-29e8-4d5b-9018-a39e1cf3ccb8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df_shuffled",
              "summary": "{\n  \"name\": \"train_df_shuffled\",\n  \"rows\": 7613,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3137,\n        \"min\": 1,\n        \"max\": 10873,\n        \"num_unique_values\": 7613,\n        \"samples\": [\n          7061,\n          843,\n          10603\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"keyword\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 221,\n        \"samples\": [\n          \"blazing\",\n          \"emergency\",\n          \"rescue\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"location\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3341,\n        \"samples\": [\n          \"617-BTOWN-BEATDOWN\",\n          \"Newcastle Upon Tyne, England\",\n          \"Federal Capital Territory\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7503,\n        \"samples\": [\n          \"This week first responders and DART members are participating in a four day intensive Technical Large Animal... http://t.co/tL93AOd3ER\",\n          \"My mom is watching a show about bridges breaking/falling and the people on them drowning in their cars aka one of my biggest fears ????\",\n          \"@NickLee8  i went to school in a bombed out East End of London3 families to one house no bathroom outside loo &amp; poor so whats yr point\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The test data doesn't have a target (that's what we'd try to predict)\n",
        "test_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "RThQFvRuNBcN",
        "outputId": "e8269d1a-c1ef-4699-afa7-17f2310baa18"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-23af273f-7188-426d-8c7a-12ba5087bf65\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-23af273f-7188-426d-8c7a-12ba5087bf65')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-23af273f-7188-426d-8c7a-12ba5087bf65 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-23af273f-7188-426d-8c7a-12ba5087bf65');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-78ea6940-400e-4604-9a5b-0a99db869561\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-78ea6940-400e-4604-9a5b-0a99db869561')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-78ea6940-400e-4604-9a5b-0a99db869561 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_df",
              "summary": "{\n  \"name\": \"test_df\",\n  \"rows\": 3263,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3146,\n        \"min\": 0,\n        \"max\": 10875,\n        \"num_unique_values\": 3263,\n        \"samples\": [\n          8051,\n          425,\n          1330\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"keyword\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 221,\n        \"samples\": [\n          \"injury\",\n          \"nuclear%20reactor\",\n          \"engulfed\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"location\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1602,\n        \"samples\": [\n          \"UAE\",\n          \"Tokio / Tokyo\",\n          \"Texas\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3243,\n        \"samples\": [\n          \"Latest: USA: Huge sinkhole swallows up Brooklyn intersection http://t.co/vspKHg3nZy\",\n          \"I liked a @YouTube video http://t.co/a5YTAw9Vih S.O.S. Rona Guide - The Red Whirlwind\",\n          \"HitchBot travels Europe and greeted with open arms. Gets destroyed after two weeks in america. There's a lesson to be learned here.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How many samples of each class?\n",
        "train_df.target.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kskwHUUQNTaz",
        "outputId": "22f50a26-6a74-49c4-d0c6-e17c75f8f6a2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "target\n",
              "0    4342\n",
              "1    3271\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_df)-5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLDUF-u2SUHe",
        "outputId": "2972f510-f938-45c6-d08c-2a831094881e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7608"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's visualize some random training examples\n",
        "import random\n",
        "random_index=random.randint(0,len(train_df)-5) # create random indexes not higher than the total number of samples\n",
        "for row in train_df_shuffled[[\"text\",\"target\"]][random_index:random_index+5].itertuples():\n",
        "  _, text, target = row\n",
        "  print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"---\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "046YQ9GYNeC0",
        "outputId": "f77f7464-a212-4889-f576-c79a5284695c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 1 (real disaster)\n",
            "Text:\n",
            "South Side factory where worker electrocuted pays $17000 penalty #Columbus - http://t.co/N8EzfCTfcE\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "Market News: Activision Blizzard Cognizant Technology First Solar http://t.co/gkNRP0e8Qs\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "#fitness Knee Damage Solution http://t.co/pUMbrNeBJE\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "Why did God order obliteration of ancient Canaanites? http://t.co/Hz4lKFfC59 via @worldnetdaily#Homosexuality is the downfall of a society.\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (real disaster)\n",
            "Text:\n",
            "70 years ago today 1945 #Hiroshima was the first nuclear atomic bomb leaving a major disaster in the wake. http://t.co/oW4GeXyNbH\n",
            "\n",
            "---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Split data into training and validation sets\n"
      ],
      "metadata": {
        "id": "9VD-Xzc6bQF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use train_test_split to split training data into training and validation sets\n",
        "train_sentences, val_sentences, train_labels, val_labels=train_test_split(train_df_shuffled[\"text\"].to_numpy(),\n",
        "                                                                        train_df_shuffled[\"target\"].to_numpy(),\n",
        "                                                                        test_size=0.1, # dedicate 10% of samples to validation set\n",
        "                                                                        random_state=42)"
      ],
      "metadata": {
        "id": "c-Db3tKebRD7"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the lengths\n",
        "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4t6coBPxcHd1",
        "outputId": "eab86ae8-9c01-4f1d-af2b-1e15ba40cf62"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 6851, 762, 762)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# View the first 10 training sentences and their labels\n",
        "train_sentences[:10], train_labels[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRwY4ekvcPDt",
        "outputId": "a156fa34-a10d-48f2-b30f-febf32500811"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "        'Imagine getting flattened by Kurt Zouma',\n",
              "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
              "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
              "        'destroy the free fandom honestly',\n",
              "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
              "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
              "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
              "       dtype=object),\n",
              " array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Converting text into numbers\n",
        "\n",
        "In NLP, there are two main concepts for turning text into numbers:\n",
        "\n",
        "**Tokenization** - A straight mapping from word or character or sub-word to a numerical value. There are three main levels of tokenization:\n",
        "\n",
        "Using word-level tokenization with the sentence \"I love TensorFlow\" might result in \"I\" being 0, \"love\" being 1 and \"TensorFlow\" being 2. In this case, every word in a sequence considered a single token.\n",
        "\n",
        "Character-level tokenization, such as converting the letters A-Z to values 1-26. In this case, every character in a sequence considered a single token.\n",
        "\n",
        "Sub-word tokenization is in between word-level and character-level tokenization. It involves breaking invidual words into smaller parts and then converting those smaller parts into numbers. For example, \"my favourite food is pineapple pizza\" might become \"my, fav, avour, rite, fo, oo, od, is, pin, ine, app, le, piz, za\". After doing this, these sub-words would then be mapped to a numerical value. In this case, every word could be considered multiple tokens.\n",
        "\n",
        "**Embeddings **- An embedding is a representation of natural language which can be learned. Representation comes in the form of a feature vector. For example, the word \"dance\" could be represented by the 5-dimensional vector [-0.8547, 0.4559, -0.3332, 0.9877, 0.1112]. It's important to note here, the size of the feature vector is tuneable. There are two ways to use embeddings:\n",
        "\n",
        "Create your own embedding - Once your text has been turned into numbers (required for an embedding), you can put them through an embedding layer (such as tf.keras.layers.Embedding) and an embedding representation will be learned during model training.\n",
        "\n",
        "Reuse a pre-learned embedding - Many pre-trained embeddings exist online. These pre-trained embeddings have often been learned on large corpuses of text (such as all of Wikipedia) and thus have a good underlying representation of natural language. You can use a pre-trained embedding to initialize your model and fine-tune it to your own specific task."
      ],
      "metadata": {
        "id": "D2XHnWjMcS51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "\n",
        "text_vectorizer=TextVectorization(max_tokens=None, # how many words in the vocabulary (all of the different words in your text)\n",
        "                                  standardize=\"lower_and_strip_punctuation\", # how to process text\n",
        "                                  split=\"whitespace\",# how to split tokens\n",
        "                                  ngrams=None, # create groups of n-words?\n",
        "                                  output_mode=\"int\", # how to map tokens to numbers\n",
        "                                  output_sequence_length=None # how long should the output sequence of tokens be?\n",
        "                                  )"
      ],
      "metadata": {
        "id": "pxMhQsTtcUFU"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find average number of tokens (words) in training Tweets\n",
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eY8rAjafbw4",
        "outputId": "dc3d1f30-3e6a-4506-a302-27bf46cefdcb"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup text vectorization with custom variables\n",
        "max_vocab_length=10000 # max number of words to have in our vocabulary\n",
        "max_length = 15 # max length our sequences will be (e.g. how many words from a Tweet does our model see?)\n",
        "\n",
        "text_vectorizer=TextVectorization(max_tokens=max_vocab_length,\n",
        "                                  output_mode='int',\n",
        "                                  output_sequence_length=max_length)"
      ],
      "metadata": {
        "id": "ujmIZK_XfuLo"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the text vectorizer to the training text\n",
        "\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "metadata": {
        "id": "tcxvcrm9gVZh"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sample sentence and tokenize it\n",
        "sample_sentence = \"There's a flood in my street!\"\n",
        "text_vectorizer([sample_sentence])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDTkccX39ix4",
        "outputId": "38baa4d9-76f1-4171-e6b2-1c03561ee901"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[264,   3, 232,   4,  13, 698,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose a random sentence from the training dataset and tokenize it\n",
        "\n",
        "random_sentance=random.choice(train_sentences)\n",
        "print(f\"original text:\\n{random_sentance}\\\n",
        "      \\n\\n Vectorize version:\")\n",
        "text_vectorizer([random_sentance])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-9QYHFt-ESK",
        "outputId": "f6a1fee6-3b22-4c33-c8c3-5798f647f8d8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original text:\n",
            "Britney Spears &gt; Vegas!! I missed you so much! ?? CanÛªt wait for the show tonight ?? #PieceOfMe \n",
            "\n",
            "?? Catastrophe ?? http://t.co/4mJyW7p7Cf      \n",
            "\n",
            " Vectorize version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[6062, 3396,  741, 3284,    8, 1810,   12,   28,  187, 2166,  637,\n",
              "          10,    2,  431,  383]])>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the unique words in the vocabulary\n",
        "words_in_vocab=text_vectorizer.get_vocabulary()\n",
        "top_5_words=words_in_vocab[:5] # most common tokens (notice the [UNK] token for \"unknown\" words)\n",
        "bottom_5_words = words_in_vocab[-5:] # least common tokens\n",
        "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
        "print(f\"Top 5 most common words: {top_5_words}\")\n",
        "print(f\"Bottom 5 least common words: {bottom_5_words}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sS2JKjxs-hAQ",
        "outputId": "a457f2f4-0114-4be3-fcec-fbbc1b34a930"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in vocab: 10000\n",
            "Top 5 most common words: ['', '[UNK]', 'the', 'a', 'in']\n",
            "Bottom 5 least common words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating an Embedding using an Embedding Layer\n",
        "\n",
        "We can see what an embedding of a word looks like by using the tf.keras.layers.Embedding layer.\n",
        "\n",
        "Creating an Embedding using an Embedding Layer\n",
        "We've got a way to map our text to numbers. How about we go a step further and turn those numbers into an embedding?\n",
        "\n",
        "The powerful thing about an embedding is it can be learned during training. This means rather than just being static (e.g. 1 = I, 2 = love, 3 = TensorFlow), a word's numeric representation can be improved as a model goes through data samples.\n",
        "\n",
        "We can see what an embedding of a word looks like by using the tf.keras.layers.Embedding layer.\n",
        "\n",
        "The main parameters we're concerned about here are:\n",
        "\n",
        "input_dim - The size of the vocabulary (e.g. len(text_vectorizer.get_vocabulary()).\n",
        "\n",
        "output_dim - The size of the output embedding vector, for example, a value of 100 outputs a feature vector of size 100 for each word.\n",
        "\n",
        "embeddings_initializer - How to initialize the embeddings matrix, default is \"uniform\" which randomly initalizes embedding matrix with uniform distribution. This can be changed for using pre-learned embeddings.\n",
        "\n",
        "input_length - Length of sequences being passed to embedding layer.\n"
      ],
      "metadata": {
        "id": "SGjTKF9TJ8K3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding=layers.Embedding(input_dim=max_vocab_length, # set input shape\n",
        "                           output_dim=128, #set size of embeding vector\n",
        "                           embeddings_initializer=\"uniform\",  # default, intialize randomly\n",
        "                           input_length=max_length, #how long is each input\n",
        "                           name=\"embedding_1\"\n",
        "                           )\n",
        "embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Vd3I4Vw_C3C",
        "outputId": "1a74ef63-d4c5-48b0-9982-c43ff1e05ca1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.layers.core.embedding.Embedding at 0x7bb2cf7bf5e0>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a random sentence from training set\n",
        "\n",
        "random_sentence=random.choice(train_sentences)\n",
        "print(f\"Original text:\\n{random_sentence}\\\n",
        "      \\n\\nEmbedded version:\")\n",
        "\n",
        "# Embed the random sentence (turn it into numerical representation)\n",
        "\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "sample_embed"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QavpKOlp_HUQ",
        "outputId": "9eaaa99a-a580-4573-b8d7-4ead940601bb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            "IS claims suicide bombing against Saudi police: An Islamic State group suicide bomber on Thursday detonated an... http://t.co/Dn5Buo7GSK      \n",
            "\n",
            "Embedded version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[-0.02865225,  0.0351986 , -0.00764841, ...,  0.0389198 ,\n",
              "         -0.01693163, -0.02944857],\n",
              "        [-0.00029763, -0.02616497,  0.00832838, ..., -0.0251544 ,\n",
              "         -0.01446981,  0.00086911],\n",
              "        [-0.03013499, -0.0051682 ,  0.03838635, ..., -0.0155264 ,\n",
              "          0.04028717, -0.03203048],\n",
              "        ...,\n",
              "        [ 0.04910055, -0.03544679,  0.00123227, ..., -0.04064655,\n",
              "          0.01208804,  0.02220771],\n",
              "        [ 0.00707463,  0.02513805, -0.00651488, ..., -0.01230575,\n",
              "          0.03087297,  0.02440763],\n",
              "        [ 0.0227927 , -0.02439126,  0.0082771 , ..., -0.03881192,\n",
              "         -0.00430522, -0.03505258]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out a single token's embedding\n",
        "sample_embed[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBe0zgiFNaQe",
        "outputId": "79e888aa-3205-421d-ca00-1a77cfb34b93"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              "array([-0.02865225,  0.0351986 , -0.00764841, -0.04955099,  0.02949378,\n",
              "        0.00014886, -0.01558714,  0.01494486, -0.02933655,  0.04810104,\n",
              "        0.04116681, -0.03546795, -0.0098931 ,  0.01826799,  0.00021046,\n",
              "       -0.01589186,  0.00107384,  0.04276116, -0.04871551, -0.02904881,\n",
              "        0.02973448,  0.01638103,  0.00118686, -0.02543724, -0.02899536,\n",
              "        0.04432644,  0.00950276, -0.01860927, -0.03483883, -0.04155598,\n",
              "        0.02341427,  0.0200381 ,  0.04439607, -0.01998763,  0.0076443 ,\n",
              "        0.01181317, -0.00170462, -0.02807562, -0.04205552, -0.02690041,\n",
              "        0.02004727,  0.00712582,  0.02282493, -0.04427906,  0.00126878,\n",
              "       -0.03942698,  0.00148703, -0.0458363 ,  0.03870593, -0.00802956,\n",
              "        0.0441024 ,  0.00859999, -0.04189966,  0.03188813,  0.01624696,\n",
              "       -0.04785326,  0.02860483, -0.03621078, -0.02301422,  0.04812546,\n",
              "        0.04948166,  0.02587496, -0.00319541, -0.01514038, -0.02594383,\n",
              "       -0.02880986, -0.01245108, -0.03334197,  0.01700658, -0.04899637,\n",
              "        0.01869174, -0.02651193,  0.02821878, -0.02054416,  0.0066892 ,\n",
              "       -0.04565361, -0.01622045, -0.03819741,  0.03012988, -0.01564151,\n",
              "        0.02924485,  0.04296646,  0.02097673, -0.02409718,  0.010418  ,\n",
              "       -0.00696968,  0.00039618,  0.03900057,  0.01311593,  0.04189612,\n",
              "        0.04914612, -0.01146949,  0.00571375,  0.0384634 , -0.00989538,\n",
              "        0.03557633, -0.01305984,  0.01957167, -0.04426246,  0.01568155,\n",
              "       -0.04555633,  0.02849314, -0.03099026,  0.04733043, -0.03469832,\n",
              "        0.01218288,  0.00148071, -0.0293952 , -0.00544226,  0.02478776,\n",
              "        0.01808215, -0.0495812 , -0.04808277,  0.03002327, -0.03270283,\n",
              "       -0.01384758,  0.01860036,  0.0054117 , -0.03785416,  0.01906523,\n",
              "       -0.03219844,  0.02892512, -0.03720338,  0.0125207 , -0.03743391,\n",
              "        0.0389198 , -0.01693163, -0.02944857], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Modelling a text dataset\n",
        "\n",
        "**Model 0**: Naive Bayes (baseline)\n",
        "\n",
        "**Model 1**: Feed-forward neural network (dense model)\n",
        "\n",
        "**Model 2**: LSTM model\n",
        "\n",
        "**Model 3**: GRU model\n",
        "\n",
        "**Model 4**: Bidirectional-LSTM model\n",
        "\n",
        "**Model 5**: 1D Convolutional Neural Network\n",
        "\n",
        "**Model 6**: TensorFlow Hub Pretrained Feature Extractor\n",
        "\n",
        "**Model 7**: Same as model 6 with 10% of training data\n"
      ],
      "metadata": {
        "id": "8LBfQQ441v6m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model 0: Getting a baseline\n",
        "\n",
        "To create our baseline, we'll create a Scikit-Learn Pipeline using the TF-IDF (term frequency-inverse document frequency) formula to convert our words to numbers and then model them with the Multinomial Naive Bayes algorithm. This was chosen via referring to the Scikit-Learn machine learning map."
      ],
      "metadata": {
        "id": "0Li37noC2GdU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create tokenization and modelling pipeline\n",
        "model_0=Pipeline([\n",
        "                  (\"tfidf\", TfidfVectorizer()), # convert words to numbers using tfidf\n",
        "                  (\"clf\", MultinomialNB()) #model the text\n",
        "                  ])\n",
        "\n",
        "## Fit the pipeline to the training data\n",
        "model_0.fit(train_sentences,train_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "XlDfd5v7SiaT",
        "outputId": "7c85817f-d7d3-402c-954e-ac7b7912ce85"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_score=model_0.score(val_sentences,val_labels)\n",
        "print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odgl3zLh3t5J",
        "outputId": "dfebf7f5-8664-4a8c-e2db-a50d5d5fbf2f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our baseline model achieves an accuracy of: 79.27%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds[:20]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwJtPXQe3_gj",
        "outputId": "2fb45558-2cd2-4781-b386-1f609a61753c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating an evaluation function for our model experiments"
      ],
      "metadata": {
        "id": "zYpCMsitvJ7H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate: accuracy, precision, recall, f1-score\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
        "\n",
        "  Args:\n",
        "  -----\n",
        "  y_true = true labels in the form of a 1D array\n",
        "  y_pred = predicted labels in the form of a 1D array\n",
        "\n",
        "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
        "  \"\"\"\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  # Calculate model precision, recall and f1 score using \"weighted\" average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                  \"precision\": model_precision,\n",
        "                  \"recall\": model_recall,\n",
        "                  \"f1\": model_f1}\n",
        "  return model_results\n"
      ],
      "metadata": {
        "id": "bnhB6gFu4CkF"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get baseline results\n",
        "baseline_results = calculate_results(y_true=val_labels,\n",
        "                                     y_pred=baseline_preds)\n",
        "baseline_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4GpUv0_w7sZ",
        "outputId": "65e1af5e-9fd4-44c1-9012-4eb9bafa2cda"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706,\n",
              " 'f1': 0.7862189758049549}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model 1: A simple dense model"
      ],
      "metadata": {
        "id": "rbNmJQN4ZxQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create tensorboard callback (need to create a new one for each model)\n",
        "from helper_functions import create_tensorboard_callback\n",
        "\n",
        "# Create directory to save TensorBoard logs\n",
        "SAVE_DIR = \"model_logs\""
      ],
      "metadata": {
        "id": "Hexz1N5kZw-D"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Build model with the Functional API\n",
        "from tensorflow.keras import layers\n",
        "inputs=layers.Input(shape=(1,), dtype=\"string\") # inputs are 1-dimensional strings\n",
        "x=text_vectorizer(inputs) #tunrn the input text into number\n",
        "x=embedding(x) #create an embedding of the numerized nubers\n",
        "x=layers.GlobalAveragePooling1D()(x) # lower the dimensionality of the embedding (try running the model without this layer and see what happens)\n",
        "outputs=layers.Dense(1,activation=\"sigmoid\")(x) # create the output layer, want binary outputs so use sigmoid activation\n",
        "model_1=tf.keras.Model(inputs, outputs, name=\"model_1_dense\") #construct the model"
      ],
      "metadata": {
        "id": "woCBXlaLaCe1"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ban6NgYFfGaV",
        "outputId": "407b49c6-1501-40d5-86f5-2458f04e159b"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_2 (Text  (None, 15)                0         \n",
            " Vectorization)                                                  \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " global_average_pooling1d (  (None, 128)               0         \n",
            " GlobalAveragePooling1D)                                         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1280129 (4.88 MB)\n",
            "Trainable params: 1280129 (4.88 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Compile model\n",
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "ZZmrAUFEfKfl"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "model_1_history=model_1.fit(train_sentences, # input sentences can be a list of strings due to text preprocessing layer built-in mode\n",
        "                            train_labels,\n",
        "                            epochs=5,\n",
        "                            validation_data=(val_sentences,val_labels),\n",
        "                            callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                   experiment_name=\"simple_dense_model\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbG8w40ykpOc",
        "outputId": "1340ecc5-0274-4c80-f4eb-c210e9ab4b6e"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/simple_dense_model/20240618-110721\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 9s 33ms/step - loss: 0.6075 - accuracy: 0.6993 - val_loss: 0.5351 - val_accuracy: 0.7533\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.4403 - accuracy: 0.8194 - val_loss: 0.4691 - val_accuracy: 0.7848\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.3458 - accuracy: 0.8613 - val_loss: 0.4590 - val_accuracy: 0.7913\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 7ms/step - loss: 0.2842 - accuracy: 0.8915 - val_loss: 0.4643 - val_accuracy: 0.7887\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.2373 - accuracy: 0.9126 - val_loss: 0.4769 - val_accuracy: 0.7874\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the results\n",
        "model_1.evaluate(val_sentences,val_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEV3c2P5mN7V",
        "outputId": "be465633-29e4-4693-9ca4-e0220f613444"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 3ms/step - loss: 0.4769 - accuracy: 0.7874\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.47687217593193054, 0.787401556968689]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding.weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rt0uwlq8mct_",
        "outputId": "8b0085c1-a413-4e0e-9567-d5ef940a463a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'embedding_1/embeddings:0' shape=(10000, 128) dtype=float32, numpy=\n",
              " array([[-0.04491668,  0.06096297,  0.03089632, ...,  0.02671579,\n",
              "         -0.02410088,  0.05725976],\n",
              "        [-0.01404313, -0.03426822,  0.00234147, ...,  0.03326145,\n",
              "         -0.02905537,  0.01875515],\n",
              "        [-0.06634224, -0.02682448,  0.01667926, ..., -0.01765694,\n",
              "          0.04893576,  0.05043369],\n",
              "        ...,\n",
              "        [-0.03885671,  0.02939147,  0.04878393, ...,  0.0420482 ,\n",
              "          0.03207195,  0.04731185],\n",
              "        [-0.03358388,  0.05806969, -0.00896139, ...,  0.02547864,\n",
              "          0.04775409,  0.0212553 ],\n",
              "        [-0.04796119,  0.10748921,  0.05651473, ...,  0.10776117,\n",
              "          0.09308806,  0.0946117 ]], dtype=float32)>]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeded_weights=model_1.get_layer(\"embedding_1\").get_weights()[0]\n",
        "print(embeded_weights.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_QFSbolIXSl",
        "outputId": "3e7adc16-109c-4035-91a8-430049ba411c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # View tensorboard logs of transfer learning modelling experiments (should be 4 models)\n",
        "# # Upload TensorBoard dev records\n",
        "# !tensorboard dev upload --logdir ./model_logs \\\n",
        "#   --name \"First deep model on text data\" \\\n",
        "#   --description \"Trying a dense model with an embedding layer\" \\\n",
        "#   --one_shot # exits the uploader when upload has finished"
      ],
      "metadata": {
        "id": "e1ARic8wI8_E"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If you need to remove previous experiments, you can do so using the following command\n",
        "# !tensorboard dev delete --experiment_id EXPERIMENT_ID_TO_DELETE"
      ],
      "metadata": {
        "id": "veJV4jQYJNtx"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions (these come back in the form of probabilities)\n",
        "\n",
        "model_1_pred_probs=model_1.predict(val_sentences)\n",
        "model_1_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7GiNpovJP-3",
        "outputId": "4b027ce2-ac23-4b64-a010-7e076969c880"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.4085023 ],\n",
              "       [0.7452258 ],\n",
              "       [0.99778676],\n",
              "       [0.1096648 ],\n",
              "       [0.10294197],\n",
              "       [0.93320936],\n",
              "       [0.91809034],\n",
              "       [0.99291843],\n",
              "       [0.96882844],\n",
              "       [0.26696762]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn prediction probabilities into single-dimension tensor of floats\n",
        "model_1_preds=tf.squeeze(tf.round(model_1_pred_probs)) #squeeze remove single dimensions\n",
        "model_1_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sLUAuu3JnU0",
        "outputId": "e325be94-0c88-45d1-d1e5-022cdc60bb07"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model_1 metrics\n",
        "model_1_results=calculate_results(y_true=val_labels,\n",
        "                                  y_pred=model_1_preds)\n",
        "model_1_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3QJLE4vKCxb",
        "outputId": "3084da14-6f6b-43bc-9a88-1752a9e576ca"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.74015748031496,\n",
              " 'precision': 0.7914920592553047,\n",
              " 'recall': 0.7874015748031497,\n",
              " 'f1': 0.7846966492209201}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Is our simple Keras model better than our baseline model?\n",
        "import numpy as np\n",
        "np.array(list(model_1_results.values()))>np.array(list(baseline_results.values()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LMyBs-rKkKq",
        "outputId": "fd0606db-5ebe-49d2-a378-0ea91bf47fc9"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a helper function to compare our baseline results to new model results\n",
        "def compare_baseline_to_new_results(baseline_results, new_model_results):\n",
        "  for key,value in baseline_results.items():\n",
        "    print(f\"Baseline {key}: {value:.2f}, New {key}: {new_model_results[key]:.2f}, Difference: {new_model_results[key]-value:.2f}\")\n",
        "\n",
        "compare_baseline_to_new_results(baseline_results=baseline_results,\n",
        "                                new_model_results=model_1_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzMopEQILK0y",
        "outputId": "e13ca1b7-606b-46ae-d3af-95c77bbf30eb"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 78.74, Difference: -0.52\n",
            "Baseline precision: 0.81, New precision: 0.79, Difference: -0.02\n",
            "Baseline recall: 0.79, New recall: 0.79, Difference: -0.01\n",
            "Baseline f1: 0.79, New f1: 0.78, Difference: -0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualizing learned embeddings\n",
        "\n",
        "Once you've downloaded the embedding vectors and metadata, you can visualize them using Embedding Vector tool:\n",
        "\n",
        "Go to http://projector.tensorflow.org/\n",
        "\n",
        "Click on \"Load data\"\n",
        "\n",
        "Upload the two files you downloaded (embedding_vectors.tsv and embedding_metadata.tsv)\n",
        "\n",
        "Explore\n",
        "\n",
        "Optional: You can share the data you've created by clicking \"Publish\"\n"
      ],
      "metadata": {
        "id": "pCAaMCCjOCxT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the vocabulary from the text vectorization layer\n",
        "words_in_vocab=text_vectorizer.get_vocabulary()\n",
        "len(words_in_vocab),words_in_vocab[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EieiN0l-N__y",
        "outputId": "927ff8f1-b218-4e5e-aa7c-954c8f2a1d0e"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Code below is adapted from: https://www.tensorflow.org/tutorials/text/word_embeddings#retrieve_the_trained_word_embeddings_and_save_them_to_disk\n",
        "# import io\n",
        "\n",
        "# # Create output writers\n",
        "# out_v = io.open(\"embedding_vectors.tsv\", \"w\", encoding=\"utf-8\")\n",
        "# out_m = io.open(\"embedding_metadata.tsv\", \"w\", encoding=\"utf-8\")\n",
        "\n",
        "# # Write embedding vectors and words to file\n",
        "# for num, word in enumerate(words_in_vocab):\n",
        "#   if num == 0:\n",
        "#      continue # skip padding token\n",
        "#   vec = embed_weights[num]\n",
        "#   out_m.write(word + \"\\n\") # write words to file\n",
        "#   out_v.write(\"\\t\".join([str(x) for x in vec]) + \"\\n\") # write corresponding word vector to file\n",
        "# out_v.close()\n",
        "# out_m.close()\n",
        "\n",
        "# # Download files locally to upload to Embedding Projector\n",
        "# try:\n",
        "#   from google.colab import files\n",
        "# except ImportError:\n",
        "#   pass\n",
        "# else:\n",
        "#   files.download(\"embedding_vectors.tsv\")\n",
        "#   files.download(\"embedding_metadata.tsv\")"
      ],
      "metadata": {
        "id": "z_q6PjHYPSt8"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Recurrent Neural Networks (RNN's)\n",
        "The premise of an RNN is simple: use information from the past to help you with the future (this is where the term recurrent comes from). In other words, take an input (X) and compute an output (y) based on all previous inputs.\n",
        "\n",
        "This concept is especially helpful when dealing with sequences such as passages of natural language text (such as our Tweets).\n",
        "\n",
        "ecurrent neural networks can be used for a number of sequence-based problems:\n",
        "\n",
        "One to one: one input, one output, such as image classification.\n",
        "\n",
        "One to many: one input, many outputs, such as image captioning (image input, a sequence of text as caption output).\n",
        "\n",
        "Many to one: many inputs, one outputs, such as text classification (classifying a Tweet as real diaster or not real diaster).\n",
        "\n",
        "Many to many: many inputs, many outputs, such as machine translation (translating English to Spanish) or speech to text (audio wave as input, text as output).\n",
        "\n",
        "When you come across RNN's in the wild, you'll most likely come across variants of the following:\n",
        "\n",
        "Long short-term memory cells (LSTMs).\n",
        "\n",
        "Gated recurrent units (GRUs).\n",
        "\n",
        "Bidirectional RNN's (passes forward and backward along a sequence, left to right and right to left).\n",
        "\n",
        "\n",
        "\n",
        " Resources:\n",
        "\n",
        "MIT Deep Learning Lecture on Recurrent Neural Networks - explains the background of recurrent neural networks and introduces LSTMs. https://youtu.be/SEnXr6v2ifU\n",
        "\n",
        "The Unreasonable Effectiveness of Recurrent Neural Networks by Andrej Karpathy - demonstrates the power of RNN's with examples generating various sequences.\n",
        "http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
        "\n",
        "Understanding LSTMs by Chris Olah - an in-depth (and technical) look at the mechanics of the LSTM cell, possibly the most popular RNN building block.\n",
        "https://colah.github.io/posts/2015-08-Understanding-LSTMs/\n"
      ],
      "metadata": {
        "id": "rT_G5fHWjJZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model 2: LSTM\n",
        "\n",
        "tensorflow.keras.layers.LSTM().\n",
        "\n",
        "Our model is going to take on a very similar structure to model_1:\n",
        "\n",
        "Input (text) -> Tokenize -> Embedding -> Layers -> Output (label probability)"
      ],
      "metadata": {
        "id": "tM6ifU6ygcFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed and create embedding layer (new embedding layer for each model)\n",
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "model_2_embedding = layers.Embedding(input_dim=max_vocab_length,\n",
        "                                     output_dim=128,\n",
        "                                     embeddings_initializer=\"uniform\",\n",
        "                                     input_length=max_length,\n",
        "                                     name=\"embedding_2\")\n",
        "#Create LSTM model\n",
        "inputs=layers.Input(shape=(1,),dtype=\"string\")\n",
        "x=text_vectorizer(inputs)\n",
        "x=model_2_embedding(x)\n",
        "print(x.shape)\n",
        "# x = layers.LSTM(64, return_sequences=True)(x) # return vector for each word in the Tweet (you can stack RNN cells as long as return_sequences=True)\n",
        "x=layers.LSTM(64)(x) # return vector for whole sequence\n",
        "print(x.shape)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer on top of output of LSTM cell\n",
        "outputs=layers.Dense(1,activation=\"sigmoid\")(x)\n",
        "model_2=tf.keras.Model(inputs,outputs,name=\"model_2_LSTM\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "R5_cbQqxkZ0_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eab9f77-33ff-4ac9-8dcd-2772698ce1c7"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 15, 128)\n",
            "(None, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Compile the model\n",
        "model_2.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "qPM8S__MgsCK"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URy1GmuDgrrs",
        "outputId": "99d80b90-35ab-4e5b-871b-4d7c41251412"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_2 (Text  (None, 15)                0         \n",
            " Vectorization)                                                  \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                49408     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1329473 (5.07 MB)\n",
            "Trainable params: 1329473 (5.07 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Fit the model\n",
        "model_2_history=model_2.fit(train_sentences,\n",
        "                            train_labels,\n",
        "                            epochs=5,\n",
        "                            validation_data=(val_sentences,val_labels),\n",
        "                            callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                   \"LSTM\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSnBM-MRk470",
        "outputId": "5d9019ba-1fca-448e-8d3a-33886daa5743"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/LSTM/20240618-110744\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 11s 38ms/step - loss: 0.5091 - accuracy: 0.7427 - val_loss: 0.4540 - val_accuracy: 0.7769\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.3176 - accuracy: 0.8707 - val_loss: 0.5167 - val_accuracy: 0.7730\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.2177 - accuracy: 0.9152 - val_loss: 0.5958 - val_accuracy: 0.7664\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.1510 - accuracy: 0.9463 - val_loss: 0.6693 - val_accuracy: 0.7769\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.1043 - accuracy: 0.9604 - val_loss: 0.8269 - val_accuracy: 0.7572\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the validation dataset\n",
        "model_2_pred_probs=model_2.predict(val_sentences)\n",
        "model_2_pred_probs.shape, model_2_pred_probs[:10]  # view the first 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pa_k0AbuldDz",
        "outputId": "3f50d133-4598-445a-d3cd-7cf10dcd75ad"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((762, 1),\n",
              " array([[0.02819953],\n",
              "        [0.7840875 ],\n",
              "        [0.9992624 ],\n",
              "        [0.10781514],\n",
              "        [0.00312637],\n",
              "        [0.9994931 ],\n",
              "        [0.9309562 ],\n",
              "        [0.99975425],\n",
              "        [0.9995952 ],\n",
              "        [0.34457895]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Round out predictions and reduce to 1-dimensional array\n",
        "model_2_preds=tf.squeeze(tf.round(model_2_pred_probs))\n",
        "model_2_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYvgAbydl3AB",
        "outputId": "7eaf1a05-0fe0-4f0c-dacf-de19f3f247b0"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate LSTM model results\n",
        "model_2_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_2_preds)\n",
        "model_2_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNSSKLdQmIfN",
        "outputId": "c4fb0b06-7de7-4255-d563-ec43762d4c67"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 75.7217847769029,\n",
              " 'precision': 0.7576149234046069,\n",
              " 'recall': 0.7572178477690289,\n",
              " 'f1': 0.7555947144839635}"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model 3: GRU\n",
        "The GRU cell has similar features to an LSTM cell but has less parameters.\n",
        "\n",
        "The architecture of the GRU-powered model will follow the same structure we've been using:\n",
        "\n",
        "Input (text) -> Tokenize -> Embedding -> Layers -> Output (label probability)"
      ],
      "metadata": {
        "id": "6ThUtg4mp538"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed and create embedding layer (new embedding layer for each model)\n",
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "model_3_embedding=layers.Embedding(input_dim=max_vocab_length,\n",
        "                                   output_dim=128,\n",
        "                                   embeddings_initializer=\"uniform\",\n",
        "                                   input_length=max_length,\n",
        "                                   name=\"embedding_3\")\n",
        "#Build an RNN using the GRU cell\n",
        "inputs=layers.Input(shape=(1,), dtype=\"string\")\n",
        "x=text_vectorizer(inputs)\n",
        "x=model_3_embedding(x)\n",
        "# x = layers.GRU(64, return_sequences=True) # stacking recurrent cells requires return_sequences=True\n",
        "x=layers.GRU(64)(x)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer after GRU cell\n",
        "outputs=layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")"
      ],
      "metadata": {
        "id": "Ua-z1kF5p5ir"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V19PREdVeQ9x"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile GRU model\n",
        "model_3.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "jgJcf6mLmMKc"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit model\n",
        "model_3_history = model_3.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"GRU\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhBg-S26rMS5",
        "outputId": "aeb916f5-e092-46d2-8d2e-200d3aea8dfe"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/GRU/20240618-110807\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 10s 38ms/step - loss: 0.5228 - accuracy: 0.7322 - val_loss: 0.4520 - val_accuracy: 0.7822\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 10ms/step - loss: 0.3182 - accuracy: 0.8704 - val_loss: 0.4897 - val_accuracy: 0.7835\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.2182 - accuracy: 0.9183 - val_loss: 0.5516 - val_accuracy: 0.7625\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.1572 - accuracy: 0.9460 - val_loss: 0.6160 - val_accuracy: 0.7795\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.1206 - accuracy: 0.9583 - val_loss: 0.5968 - val_accuracy: 0.7730\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the validation data\n",
        "model_3_pred_probs = model_3.predict(val_sentences)\n",
        "model_3_pred_probs.shape, model_3_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFj-35T2rN0g",
        "outputId": "9d0a8ca7-872f-495d-c85a-74abf0ba22bf"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((762, 1),\n",
              " array([[0.36616996],\n",
              "        [0.88703465],\n",
              "        [0.99654406],\n",
              "        [0.12461372],\n",
              "        [0.01471544],\n",
              "        [0.98945504],\n",
              "        [0.7119093 ],\n",
              "        [0.9976386 ],\n",
              "        [0.99676406],\n",
              "        [0.31322432]], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert prediction probabilities to prediction classes\n",
        "model_3_preds=tf.squeeze(tf.round(model_3_pred_probs))\n",
        "model_3_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PGa1_Mur3YC",
        "outputId": "f05e4fbf-1f1f-4585-aeb3-c0f82a0ffad6"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcuate model_3 results\n",
        "model_3_results=calculate_results(y_true=val_labels,\n",
        "                                  y_pred=model_3_preds)\n",
        "model_3_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G69lA_PXwMAQ",
        "outputId": "1616d45c-cb14-46c6-c328-0582c81e6c52"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 77.29658792650919,\n",
              " 'precision': 0.7727060691282619,\n",
              " 'recall': 0.7729658792650919,\n",
              " 'f1': 0.7722420798695805}"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare to baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_3_results)"
      ],
      "metadata": {
        "id": "6mdv6dmywbRv",
        "outputId": "a2613d8a-1034-423f-b813-7098369a29e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 77.30, Difference: -1.97\n",
            "Baseline precision: 0.81, New precision: 0.77, Difference: -0.04\n",
            "Baseline recall: 0.79, New recall: 0.77, Difference: -0.02\n",
            "Baseline f1: 0.79, New f1: 0.77, Difference: -0.01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model 4: Bidirectonal RNN model\n",
        "\n",
        "A standard RNN will process a sequence from left to right, where as a bidirectional RNN will process the sequence from left to right and then again from right to left.\n",
        "\n",
        "Intuitively, this can be thought of as if you were reading a sentence for the first time in the normal fashion (left to right) but for some reason it didn't make sense so you traverse back through the words and go back over them again (right to left).\n",
        "\n",
        "In practice, many sequence models often see and improvement in performance when using bidirectional RNN's.\n",
        "\n",
        "However, this improvement in performance often comes at the cost of longer training times and increased model parameters (since the model goes left to right and right to left, the number of trainable parameters doubles)."
      ],
      "metadata": {
        "id": "wss_QDOEORhh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed and create embedding layer (new embedding layer for each model)\n",
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "model_4_embedding=layers.Embedding(input_dim=max_vocab_length,\n",
        "                                   output_dim=128,\n",
        "                                   embeddings_initializer=\"uniform\",\n",
        "                                   input_length=max_length,\n",
        "                                   name=\"embedding_4\")\n",
        "# Build a Bidirectional RNN in TensorFlow\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = model_4_embedding(x)  # Reuse embedding layer if desired\n",
        "\n",
        "# x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x) # stacking RNN layers requires return_sequences=True\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x) # bidirectional goes both ways so has double the parameters of a regular LSTM layer\n",
        "\n",
        "\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_Bidirectional\")"
      ],
      "metadata": {
        "id": "QxBbiw6fwfvY"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a summary of our bidirectional model\n",
        "model_4.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5NwYSLeR-ux",
        "outputId": "782df084-4076-4c21-873b-6890108f9096"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4_Bidirectional\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_2 (Text  (None, 15)                0         \n",
            " Vectorization)                                                  \n",
            "                                                                 \n",
            " embedding_4 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 128)               98816     \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1378945 (5.26 MB)\n",
            "Trainable params: 1378945 (5.26 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_4.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "rrqh2GRweSr6"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model (takes longer because of the bidirectional layers)\n",
        "model_4_history = model_4.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR, \"bidirectional_RNN\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmtYT8rpefhU",
        "outputId": "81df5346-d0eb-427a-f29e-0d347439b9be"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/bidirectional_RNN/20240618-110830\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 12s 41ms/step - loss: 0.5104 - accuracy: 0.7425 - val_loss: 0.4600 - val_accuracy: 0.7808\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.3145 - accuracy: 0.8723 - val_loss: 0.5097 - val_accuracy: 0.7743\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.2148 - accuracy: 0.9181 - val_loss: 0.5653 - val_accuracy: 0.7795\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.1522 - accuracy: 0.9470 - val_loss: 0.6348 - val_accuracy: 0.7756\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.1107 - accuracy: 0.9628 - val_loss: 0.6635 - val_accuracy: 0.7638\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_4_pred_probs=model_4.predict(val_sentences)\n",
        "model_4_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWt3BhgTUVm8",
        "outputId": "b4b891a1-422d-491e-f033-092121af9f49"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 4ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.12844808],\n",
              "       [0.90346795],\n",
              "       [0.9993573 ],\n",
              "       [0.15998428],\n",
              "       [0.0103102 ],\n",
              "       [0.99630773],\n",
              "       [0.91975147],\n",
              "       [0.999671  ],\n",
              "       [0.999624  ],\n",
              "       [0.3332004 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert prediction probabilities to labels\n",
        "model_4_preds=tf.squeeze(tf.round(model_4_pred_probs))\n",
        "model_4_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTGIFHBYUol0",
        "outputId": "0c23d1eb-9052-45bb-ea98-96a55a7b4763"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate bidirectional RNN model results\n",
        "model_4_results = calculate_results(val_labels, model_4_preds)\n",
        "model_4_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JBti8txVt61",
        "outputId": "b2eeabbd-7596-412c-c23e-a74e271ece27"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 76.37795275590551,\n",
              " 'precision': 0.7634196497878314,\n",
              " 'recall': 0.7637795275590551,\n",
              " 'f1': 0.7634672340254871}"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check to see how the bidirectional model performs against the baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_4_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efdZFBNyV9TN",
        "outputId": "9b619312-9a17-40eb-affd-1a3e28c19007"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 76.38, Difference: -2.89\n",
            "Baseline precision: 0.81, New precision: 0.76, Difference: -0.05\n",
            "Baseline recall: 0.79, New recall: 0.76, Difference: -0.03\n",
            "Baseline f1: 0.79, New f1: 0.76, Difference: -0.02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Convolutional Neural Networks for Text\n",
        "\n",
        "The main difference between using CNNs for images and sequences is the shape of the data. Images come in 2-dimensions (height x width) where as sequences are often 1-dimensional (a string of text).\n",
        "\n",
        "A typical CNN architecture for sequences will look like the following:\n",
        "\n",
        "Inputs (text) -> Tokenization -> Embedding -> Layers -> Outputs (class probabilities)\n",
        "\n"
      ],
      "metadata": {
        "id": "dQj9mas2W9YC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model 5: Conv1D"
      ],
      "metadata": {
        "id": "YahCB1cvbhpP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed and create embedding layer (new embedding layer for each model)\n",
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "model_5_embedding=layers.Embedding(input_dim=max_vocab_length,\n",
        "                                   output_dim=128,\n",
        "                                   embeddings_initializer=\"uniform\",\n",
        "                                   input_length=max_length,\n",
        "                                   name=\"embedding_5\")\n",
        "\n",
        "# Create 1-dimensional convolutional layer to model sequences\n",
        "inputs=layers.Input(shape=(1,), dtype=\"string\")\n",
        "x=text_vectorizer(inputs)\n",
        "x=model_5_embedding(x)\n",
        "x=layers.Conv1D(filters=32, kernel_size=5, activation='relu')(x)\n",
        "x=layers.GlobalAveragePooling1D()(x)\n",
        "# x = layers.Dense(64, activation=\"relu\")(x) # optional dense layer\n",
        "outputs=layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_5=tf.keras.Model(inputs,outputs, name=\"model_5_Conv1D\")"
      ],
      "metadata": {
        "id": "cJ7DF1WiWCQs"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_5.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBb4RBoXeO3H",
        "outputId": "f87807ad-1193-47dd-b954-cdf120be5bb6"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5_Conv1D\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_2 (Text  (None, 15)                0         \n",
            " Vectorization)                                                  \n",
            "                                                                 \n",
            " embedding_5 (Embedding)     (None, 15, 128)           1280000   \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 11, 32)            20512     \n",
            "                                                                 \n",
            " global_average_pooling1d_1  (None, 32)                0         \n",
            "  (GlobalAveragePooling1D)                                       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1300545 (4.96 MB)\n",
            "Trainable params: 1300545 (4.96 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Compile the model\n",
        "\n",
        "model_5.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "_MrpS80Kd2q_"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "model_5_history = model_5.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"Conv1D\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBBO4fVyeJ4d",
        "outputId": "808a3494-0946-4f1d-e4bc-da2496e00f51"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/Conv1D/20240618-110855\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 10s 34ms/step - loss: 0.5362 - accuracy: 0.7355 - val_loss: 0.4676 - val_accuracy: 0.7835\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 11ms/step - loss: 0.3380 - accuracy: 0.8596 - val_loss: 0.5062 - val_accuracy: 0.7861\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.2341 - accuracy: 0.9108 - val_loss: 0.5780 - val_accuracy: 0.7677\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 7ms/step - loss: 0.1704 - accuracy: 0.9342 - val_loss: 0.6657 - val_accuracy: 0.7690\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.1283 - accuracy: 0.9508 - val_loss: 0.7716 - val_accuracy: 0.7585\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#MAke predictions\n",
        "model_5_pred_probs=model_5.predict(val_sentences)\n",
        "model_5_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-B-3oU0OfcjE",
        "outputId": "c09e37dd-2186-447c-f355-2e67b0cc386e"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.53302705],\n",
              "       [0.82562643],\n",
              "       [0.99999845],\n",
              "       [0.01913047],\n",
              "       [0.01474809],\n",
              "       [0.9900802 ],\n",
              "       [0.7979824 ],\n",
              "       [0.99972254],\n",
              "       [0.99999666],\n",
              "       [0.18314233]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QpcHCbExbf53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert model_5 prediction probabilities to labels\n",
        "model_5_preds=tf.squeeze(tf.round(model_5_pred_probs))\n",
        "model_5_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNME-FVoftgT",
        "outputId": "6fd92411-b3df-42f5-82db-46752b401cc1"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([1., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model_5 evaluation metrics\n",
        "model_5_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_5_preds)\n",
        "model_5_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hj72AyJff-u7",
        "outputId": "53d34344-2146-4216-e37f-6611aea08c3f"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 75.8530183727034,\n",
              " 'precision': 0.7581370877027468,\n",
              " 'recall': 0.7585301837270341,\n",
              " 'f1': 0.7578056664430846}"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare model_5 results to baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_5_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnCD3pA1gEVT",
        "outputId": "ee2c824b-7c25-4ced-ed41-4bae1abee71f"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 75.85, Difference: -3.41\n",
            "Baseline precision: 0.81, New precision: 0.76, Difference: -0.05\n",
            "Baseline recall: 0.79, New recall: 0.76, Difference: -0.03\n",
            "Baseline f1: 0.79, New f1: 0.76, Difference: -0.03\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Using Pretrained Embeddings (transfer learning for NLP)\n",
        "\n",
        "A common practice is to leverage pretrained embeddings through transfer learning. This is one of the main benefits of using deep models: being able to take what one (often larger) model has learned (often on a large amount of data) and adjust it for our own use case.\n",
        "We're going to be using the Universal Sentence Encoder from TensorFlow Hub\n"
      ],
      "metadata": {
        "id": "Y_x9zmWN-l9g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model 6: TensorFlow Hub Pretrained Sentence Encoder\n",
        "\n",
        "The main difference between the embedding layer we created and the Universal Sentence Encoder is that rather than create a word-level embedding, the Universal Sentence Encoder, as you might've guessed, creates a whole sentence-level embedding.\n"
      ],
      "metadata": {
        "id": "luK9Wz1L-2gh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of pretrained embedding with universal sentence encoder - https://tfhub.dev/google/universal-sentence-encoder/4\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "embed=hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\") # load Universal Sentence Encoder\n",
        "embed_samples=embed([sample_sentence,\n",
        "                     \"When you call the universal sentence encoder on a sentence, it turns it into numbers.\"])\n",
        "print(embed_samples[0][:50])"
      ],
      "metadata": {
        "id": "9Z2NozNCgGkS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "545f8d1b-f9a7-4536-97de-0b29f4a8aec8"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[-0.01157028  0.0248591   0.02878048 -0.012715    0.03971538  0.0882776\n",
            "  0.02680984  0.05589836 -0.0106873  -0.00597291  0.00639323 -0.01819518\n",
            "  0.00030813  0.09105888  0.05874644 -0.03180628  0.01512474 -0.05162929\n",
            "  0.00991367 -0.06865347 -0.04209306  0.02678981  0.03011006  0.00321069\n",
            " -0.00337973 -0.04787357  0.0226672  -0.00985925 -0.04063613 -0.01292092\n",
            " -0.04666384  0.05630299 -0.03949255  0.00517686  0.02495829 -0.0701444\n",
            "  0.02871508  0.04947684 -0.00633979 -0.08960192  0.02807118 -0.00808364\n",
            " -0.01360602  0.0599865  -0.10361787 -0.05195374  0.00232954 -0.02332531\n",
            " -0.03758105  0.03327728], shape=(50,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Each sentence has been encoded into a 512 dimension vector\n",
        "embed_samples[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWl3zVm7_znz",
        "outputId": "4922088f-fc3d-4b5f-d319-7d782af0320a"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([512])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passing our sentences to the Universal Sentence Encoder (USE) encodes them from strings to 512 dimensional vectors, which make no sense to us but hopefully make sense to our machine learning models.\n",
        "\n",
        "Speaking of models, let's build one with the USE as our embedding layer.\n",
        "\n",
        "We can convert the TensorFlow Hub USE module into a Keras layer using the hub.KerasLayer class.\n",
        "\n",
        "🔑 Note: Due to the size of the USE TensorFlow Hub module, it may take a little while to download. Once it's downloaded though, it'll be cached and ready to use. And as with many TensorFlow Hub modules, there is a \"lite\" version of the USE which takes up less space but sacrifices some performance and requires more preprocessing steps. However, depending on your available compute power, the lite version may be better for your application use case."
      ],
      "metadata": {
        "id": "jmcImmHKCtcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We can use this encoding layer in place of our text_vectorizer and embedding layer\n",
        "sentence_encoder_layer=hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                      input_shape=[], # shape of inputs coming to our model\n",
        "                                      dtype=tf.string, # data type of inputs coming to the USE layer\n",
        "                                      trainable=False, # keep the pretrained weights (we'll create a feature extractor)\n",
        "                                      name=\"USE\")"
      ],
      "metadata": {
        "id": "Dj47qEHjCtOt"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create model using the Sequential API\n",
        "model_6=tf.keras.Sequential([\n",
        "    sentence_encoder_layer, # take in sentences and then encode them into an embedding\n",
        "    layers.Dense(64,activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "],name=\"model_6_USE\")\n"
      ],
      "metadata": {
        "id": "2S4Ov6KvExOB"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_6.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "model_6.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Un8kaWh1FaUg",
        "outputId": "cde62a7e-d304-4c0a-d310-9a412092bdf2"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " USE (KerasLayer)            (None, 512)               256797824 \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 64)                32832     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256830721 (979.73 MB)\n",
            "Trainable params: 32897 (128.50 KB)\n",
            "Non-trainable params: 256797824 (979.61 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a classifier on top of pretrained embeddings\n",
        "model_6_history=model_6.fit(train_sentences,\n",
        "                            train_labels,\n",
        "                            epochs=5,\n",
        "                            validation_data=(val_sentences,val_labels),\n",
        "                            callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                   \"tf_hub_sentence_encoder\")])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjBGHPFfFgx6",
        "outputId": "b78d621e-a526-4428-d977-901855263c1b"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder/20240618-112501\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 8s 14ms/step - loss: 0.5063 - accuracy: 0.7853 - val_loss: 0.4484 - val_accuracy: 0.8005\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 12ms/step - loss: 0.4146 - accuracy: 0.8135 - val_loss: 0.4367 - val_accuracy: 0.8123\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.3996 - accuracy: 0.8210 - val_loss: 0.4321 - val_accuracy: 0.8136\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 5s 23ms/step - loss: 0.3919 - accuracy: 0.8260 - val_loss: 0.4277 - val_accuracy: 0.8150\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 14ms/step - loss: 0.3855 - accuracy: 0.8292 - val_loss: 0.4293 - val_accuracy: 0.8163\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions with USE TF Hub model\n",
        "model_6_pred_probs = model_6.predict(val_sentences)\n",
        "model_6_pred_probs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x-fxvlWNGCaR",
        "outputId": "3c4479c5-374c-466e-9f22-87a01efa83f6"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 1s 15ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.15399648],\n",
              "       [0.75121224],\n",
              "       [0.98957133],\n",
              "       [0.21155609],\n",
              "       [0.71394986],\n",
              "       [0.6854042 ],\n",
              "       [0.98330575],\n",
              "       [0.97589046],\n",
              "       [0.92347026],\n",
              "       [0.08086   ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert prediction probabilities to labels\n",
        "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
        "model_6_preds[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJvKUTBYGHJ5",
        "outputId": "215fa63f-e677-42c4-8458-19c518723e9e"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model 6 performance metrics\n",
        "model_6_results = calculate_results(val_labels, model_6_preds)\n",
        "model_6_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjOhiYIOGHgJ",
        "outputId": "c3011d0b-86af-44dc-bccf-428527f21b8a"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 81.62729658792651,\n",
              " 'precision': 0.8194307529740601,\n",
              " 'recall': 0.8162729658792651,\n",
              " 'f1': 0.8145018782850012}"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare TF Hub model to baseline\n",
        "compare_baseline_to_new_results(baseline_results, model_6_results)"
      ],
      "metadata": {
        "id": "-T3EOrrlGJ1C",
        "outputId": "786be089-3e69-41dc-e9d2-30de64fb38b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy: 79.27, New accuracy: 81.63, Difference: 2.36\n",
            "Baseline precision: 0.81, New precision: 0.82, Difference: 0.01\n",
            "Baseline recall: 0.79, New recall: 0.82, Difference: 0.02\n",
            "Baseline f1: 0.79, New f1: 0.81, Difference: 0.03\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vrWbpHPAGMYZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}